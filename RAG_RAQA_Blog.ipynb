{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdabir1203/42_WOB_AI_Community/blob/main/RAG_RAQA_Blog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FCz0cvWF_wbA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install -q -U faiss-cpu tiktoken\n",
        "!pip3 install cerebrium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gnISdj8lMqKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b22caa-1cf0-44ad-d7da-e8d446c12ba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CEREBRIUM API Key:··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"CEREBRIUMAI_API_KEY\"] = getpass.getpass(\"CEREBRIUM API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tzvxysqcZCLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiCAlO7L-VlD"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Large Language Models (LLMs) are powerful tools for generating human-like text, but they have limitations.\n",
        "\n",
        "Retrieval Augmented Generation (RAG) addresses these challenges, enhancing LLMs by integrating retrieval mechanisms. This approach ensures that the content LLMs produce is both contextually relevant and factually accurate. RAG acts as a bridge, connecting LLMs to vast knowledge sources. As AI becomes increasingly used for diverse tasks, the accuracy and relevance of the generated information are crucial.\n",
        "\n",
        "RAG meets this demand, making AI interactions more informative and context-aware.\n",
        "\n",
        "# What You Need for RAG Implementation\n",
        "\n",
        "Before building out a RAG system, it's essential to familiarize yourself with the tools that make this process possible.\n",
        "\n",
        "Each tool plays a specific role, ensuring that the RAG system operates efficiently and effectively.\n",
        "\n",
        "**LLM**: At the heart of the system is the LLM, the core AI model responsible for generating human-like text responses.\n",
        "\n",
        "**Vector Store**: This is where the magic happens. The Vector Store is a dedicated storage system that houses embeddings and their corresponding textual data, ensuring quick and efficient retrieval.\n",
        "\n",
        "**Vector Store Retriever**: Think of this as the search engine of the system. The Vector Store Retriever fetches relevant documents by comparing vector similarities, ensuring that the most pertinent information is always at hand.\n",
        "\n",
        "**Embedder**: Before storing or retrieving data, we need to convert textual information into a format the system can understand. The Embedder takes on this role, transforming text into vector representations.\n",
        "\n",
        "**Prompt**: Every interaction starts with a user's query or statement. The Prompt captures this initial input, setting the stage for the retrieval and generation processes.\n",
        "\n",
        "**Document Loader**: With vast amounts of data to process, the Document Loader is essential. It imports and reads documents, preparing them for chunking and embedding.\n",
        "\n",
        "**Document Chunker**: To make the data more manageable and efficient for retrieval, the Document Chunker breaks documents into smaller, more digestible pieces.\n",
        "\n",
        "**User Input**: Last but not least, the User Input tool captures the query or statement provided by the end-user, initiating the entire RAG process.\n",
        "\n",
        "\n",
        "# The RAG System and Its Subsystems\n",
        "\n",
        "The primary goal of RAG is to provide LLMs with contextually relevant and factually accurate information, ensuring that the generated content meets the highest standards of quality and relevance.\n",
        "\n",
        "To achieve this, the RAG system is divided into subsystems, each playing a crucial role in the overall process. The tools integral to the RAG system are not standalone entities; they interweave to form the subsystems that drive the RAG process.\n",
        "\n",
        "Each tool fits within one of the following subsystems:\n",
        "\n",
        "1) Index\n",
        "\n",
        "2) Retrieval\n",
        "\n",
        "3) Augment\n",
        "\n",
        "These work together as an orchestrated flow that transforms a user's query into a contextually rich and accurate response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9o1pzeRkXUT"
      },
      "source": [
        "# Index System\n",
        "\n",
        "**Purpose:** This subsystem is responsible for preparing and organizing the data for efficient retrieval.\n",
        "\n",
        "Here are the steps of the Index system\n",
        "\n",
        "**1) Load Documents (Document Loader)**: Imports and reads the vast amounts of data that the system will use.\n",
        "\n",
        "**2) Chunk Documents (Document Chunker):** Breaks down the loaded documents into smaller, more manageable pieces to facilitate efficient retrieval.\n",
        "\n",
        "**3) Embed Documents (Embedder):** Converts these textual chunks into vector representations, making them searchable within the system.\n",
        "\n",
        "**4) Store Embeddings (Vector Store):** Safely stores the generated embeddings alongside their textual counterparts for future retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK3gf7TDH9GS"
      },
      "source": [
        "### Load documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nmKgqy5X_vhA"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "\n",
        "yolo_nas_loader = WebBaseLoader(\"https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd\").load()\n",
        "\n",
        "decicoder_loader = WebBaseLoader(\"https://medium.com/@md.abir1203/bytecode-the-bridge-between-code-and-machine-beeffb9ba91c\").load()\n",
        "\n",
        "#yolo_newsletter_loader = WebBaseLoader(\"https://deeplearningdaily.substack.com/p/unleashing-the-power-of-yolo-nas\").load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1shOpId_vqb"
      },
      "source": [
        "### Chunk documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fuXm06J1IDs7"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 700,\n",
        "    chunk_overlap = 50,\n",
        "    length_function = len\n",
        ")\n",
        "\n",
        "yolo_nas_chunks = text_splitter.transform_documents(yolo_nas_loader)\n",
        "\n",
        "decicoder_chunks = text_splitter.transform_documents(decicoder_loader)\n",
        "\n",
        "#yolo_newsletter_chunks = text_splitter.transform_documents(yolo_newsletter_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yolo_nas_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGLDkzmejA1B",
        "outputId": "a30aed1c-a88c-4295-efc4-5e6dc3ddc83a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | MediumOpen in appSign upSign inWriteSign upSign inHave you heard about Memory Management called Arena ?UknOwWho_Ab1r·Follow4 min read·4 days ago--ListenShareIt’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is related with the Automotive domain. Speaking of it, let’s delve into a concept called Arena Memory Management.Arena Memory ManagementArena Memory Management offers a compelling solution to the challenges of traditional memory management techniques. By', metadata={'source': 'https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd', 'title': 'Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | Medium', 'description': 'It’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is…', 'language': 'en'}), Document(page_content='of traditional memory management techniques. By rethinking the underlying principles and operating on large, contiguous blocks of memory called “arenas”, it significantly reduces fragmentation, improves performance, and simplifies the development process.Code Example#include <cstddef>#include <new>#include <vector>#include <cstdint>#include <iostream>class ArenaAllocator{public:    ArenaAllocator(std::size_t size) : _memory(new char[size]), _size(size), _current(_memory) {}    ~ArenaAllocator()    {        delete[] _memory;    }    void *allocate(std::size_t size, std::size_t alignment = alignof(std::max_align_t))    {        void *result = nullptr;        std::size_t space_left = _size -', metadata={'source': 'https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd', 'title': 'Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | Medium', 'description': 'It’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is…', 'language': 'en'}), Document(page_content='nullptr;        std::size_t space_left = _size - (_current - _memory);        if (space_left >= size)        {            // Calculate the adjustment needed to align the memory            std::size_t adjustment = alignment - ((std::uintptr_t)_current % alignment);            if (adjustment == alignment)                adjustment = 0; // Already aligned            if (space_left >= size + adjustment)            {                result = _current + adjustment;                  _current += size + adjustment; // 152 -> ((100 + 50) + 2).            }        }        return result;    }    void reset()    {        _current = _memory;    }private:    char *_memory;    std::size_t _size;    char', metadata={'source': 'https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd', 'title': 'Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | Medium', 'description': 'It’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is…', 'language': 'en'}), Document(page_content='char *_memory;    std::size_t _size;    char *_current;};int main(){    // Create an ArenaAllocator object with a size of 1000 bytes    ArenaAllocator allocator(1000);    // Allocate memory from the arena for three different chunks    void *ptr1 = allocator.allocate(100); // Allocating 100 bytes    void *ptr2 = allocator.allocate(200); // Allocating 200 bytes    void *ptr3 = allocator.allocate(300); // Allocating 300 bytes    // Check if allocations were successful    if (ptr1 && ptr2 && ptr3)    {        std::cout << \"Allocations successful!\" << std::endl;        // Print the addresses of allocated memory        std::cout << \"ptr1 address: \" << ptr1 << std::endl;        std::cout <<', metadata={'source': 'https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd', 'title': 'Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | Medium', 'description': 'It’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is…', 'language': 'en'}), Document(page_content='\" << ptr1 << std::endl;        std::cout << \"ptr2 address: \" << ptr2 << std::endl;        std::cout << \"ptr3 address: \" << ptr3 << std::endl;        // Reset the allocator to reuse the memory space        allocator.reset();        std::cout << \"Allocator reset.\" << std::endl;        // Reallocate memory from the same arena for a larger chunk        void *ptr4 = allocator.allocate(400); // Allocating 400 bytes        if (ptr4)        {            std::cout << \"Re-allocation successful!\" << std::endl;            std::cout << \"ptr4 address: \" << ptr4 << std::endl;        }        else        {            std::cout << \"Re-allocation failed!\" << std::endl;        }    }    else    {', metadata={'source': 'https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd', 'title': 'Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | Medium', 'description': 'It’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is…', 'language': 'en'}), Document(page_content='<< std::endl;        }    }    else    {        std::cout << \"Allocation failed!\" << std::endl;    }    return 0;}OUTPUTWe can see from the above code examples how arena helps allocating block of memory for ex: 100 bytes each and then reallocate again to fix memory reallocation. Also we can see how the arena allocator can efficiently manage and reuse memory space.TRADEOFFWhile Arena Memory Management has proven its worth in various performance-critical applications, it’s important to be aware of its limitations and tradeoffs:Fixed Memory Budget: Arena Memory Management requires a fixed memory budget, which may not be suitable for applications with highly dynamic memory usage patterns. If', metadata={'source': 'https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd', 'title': 'Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | Medium', 'description': 'It’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is…', 'language': 'en'}), Document(page_content='with highly dynamic memory usage patterns. If the arena size is not carefully chosen, it can lead to either wasted memory or frequent arena reallocations, which can negate some of the performance benefits.X: Allocated Memory || ‘.’ : Empty MemoryExternal Fragmentation: While Arena Memory Management eliminates internal fragmentation within an arena, it can still be susceptible to external fragmentation if the arena size is not carefully managed. Over time, as arenas are allocated and freed, the memory space can become fragmented, leading to potential performance issues.Integration Challenges: Integrating Arena Memory Management into existing codebases can be a non-trivial task, especially if', metadata={'source': 'https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd', 'title': 'Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | Medium', 'description': 'It’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is…', 'language': 'en'}), Document(page_content='can be a non-trivial task, especially if the codebase relies heavily on traditional memory management techniques. It may require significant refactoring and careful planning to ensure a smooth transition.A Mermaid VisualizationLack of Automatic Deallocation: Unlike traditional memory management techniques, Arena Memory Management does not automatically deallocate memory when objects go out of scope. Developers must manually manage the lifetime of arenas, which can introduce new sources of memory leaks if not handled correctly.Compatibility Issues:Arena Memory Management, despite its advantages, can encounter compatibility challenges when paired with certain programming language features or', metadata={'source': 'https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd', 'title': 'Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | Medium', 'description': 'It’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is…', 'language': 'en'}), Document(page_content='with certain programming language features or third-party libraries that depend on traditional memory management techniques.For instance, a project integrating a third-party graphics rendering library that employs methods like new and delete for memory handling may encounter issues upon transitioning to Arena Memory Management.Despite these limitations, Arena Memory Management can be a powerful arsenal in the developer’s toolkit, especially for performance-critical applications where memory management is a bottleneck.By weighing the tradeoffs and designing systems that play to the strengths of Arena Memory Management, a developer can unlock significant performance gains and simplify their', metadata={'source': 'https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd', 'title': 'Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | Medium', 'description': 'It’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is…', 'language': 'en'}), Document(page_content='significant performance gains and simplify their memory management workflows.References: - https://stackoverflow.com/questions/12825148/what-is-the-meaning-of-the-term-arena-in-relation-to-memory- https://www.rfleury.com/p/untangling-lifetimes-the-arena-allocator- https://en.wikipedia.org/wiki/Region-based_memory_managementIf you find any mistakes or would like to have more elaborate discussion feel free to connect to me in linkedin / write in the comments below.----FollowWritten by UknOwWho_Ab1r65 FollowersSoftware Engineer | Mechanical Engineer | Redis Side Quest Hackathon Winner | Gen AI EnthusiastFollowHelpStatusAboutCareersBlogPrivacyTermsText to speechTeams', metadata={'source': 'https://medium.com/@md.abir1203/have-you-heard-about-memory-management-called-arena-4a515b990fbd', 'title': 'Have you heard about Memory Management called Arena ? | by UknOwWho_Ab1r | Apr, 2024 | Medium', 'description': 'It’s been quite a while as I wanted to take a break from the Large Language Model World and come back to my old interest of Memory Management in C/C++ which kind of intrigues me the most as it is…', 'language': 'en'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGzRpURwJqHM"
      },
      "source": [
        "### Create an index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "iGtfN_hiJzVB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0a2cbab83c45400cb700856842884a5f",
            "f03bd4473e4a4e3fa367d217fe35a967",
            "d86aa4ee08774a6c93339efed4494e62",
            "4d2e5394611d4f329086b0b027c711e1",
            "e86b649aef4f4ccf92285a22da674660",
            "f656d2849a2e407a9a68ec149fa336ac",
            "79140df95ca54de3b982f6d1a020fa3b",
            "343b915e04ea4421a6d18c0cff735621",
            "a2e625b76ff14f2bac32458e402a37e7",
            "cdcbb7cd39e8483283c686dab62b127f",
            "634ea3ab03d24ed6828bd272c54bd733"
          ]
        },
        "outputId": "b8a9496e-740c-4638-e97d-dc0ef2bfcbf6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a2cbab83c45400cb700856842884a5f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_community.llms import CerebriumAI\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "\n",
        "\n",
        "store = LocalFileStore(\"./cachce/\")\n",
        "\n",
        "# create an embedder\n",
        "core_embeddings_model = FastEmbedEmbeddings()\n",
        "\n",
        "\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    core_embeddings_model,\n",
        "    store,\n",
        ")\n",
        "\n",
        "# store embeddings in vector store\n",
        "vectorstore = FAISS.from_documents(yolo_nas_chunks, embedder)\n",
        "\n",
        "vectorstore.add_documents(decicoder_chunks)\n",
        "\n",
        "#vectorstore.add_documents(yolo_newsletter_chunks)\n",
        "\n",
        "# instantiate a retriever\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4HNkh6pmQ61"
      },
      "source": [
        "# Retrieval System\n",
        "\n",
        "**Purpose:** As the name suggests, this subsystem fetches the most relevant information based on the user's query.\n",
        "\n",
        "Here are the steps in the Retrieval system\n",
        "\n",
        "**1) Obtain User Query (User Input):** Captures the user's question or statement.\n",
        "\n",
        "**2) Embed User Query (Embedder):** Transforms the user's query into a vector format, similar to the indexed documents.\n",
        "\n",
        "**3) Vector Search (Vector Store Retriever):** Searches the Vector Store for documents with embeddings that closely match the embedded user query.\n",
        "\n",
        "**4) Return Relevant Documents:** The system then returns the top matches, ensuring that the most pertinent information is always provided.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Eq3nKNJ2mRDK"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import CerebriumAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "D9FGhpMWORwa",
        "outputId": "f55df8c9-e51e-4494-a3c8-ca597d0cf4b9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'llm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-9acda54467a8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mllm_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mStdOutCallbackHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
          ]
        }
      ],
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "handler =  StdOutCallbackHandler()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHxHCbfLj19N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "ypEuSFtjjrfK"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uBhaA_nkpU_2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f01e20c0-7638-4a62-a0fb-0971c83479da"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'llm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-660d7796b040>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this is the entire retrieval system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m qa_with_sources_chain = RetrievalQA.from_chain_type(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mretriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
          ]
        }
      ],
      "source": [
        "# this is the entire retrieval system\n",
        "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    callbacks=[handler],\n",
        "    return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAaIa-kpsHHI"
      },
      "source": [
        "# Augment System\n",
        "\n",
        "**Purpose:** This subsystem enhances the LLM's input prompt with the retrieved context, ensuring that the model has all the necessary information to generate a comprehensive response.\n",
        "\n",
        "**1) Create Initial Prompt (Prompt):** Starts with the original user query or statement.\n",
        "\n",
        "**2) Augment Prompt with Retrieved Context:** Merges the initial prompt with the context retrieved from the Vector Store, creating an enriched input for the LLM.\n",
        "\n",
        "**3) Send Augmented Prompt to LLM:** The enhanced prompt is then fed to the LLM.\n",
        "\n",
        "**4) Receive LLM's Response:** After processing the augmented prompt, the LLM generates and returns its response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-NO6i0YS6nY",
        "outputId": "1471855a-4155-4e86-ace9-70a9c1a7596c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# This is the entire augment system!\n",
        "response = qa_with_sources_chain({\"query\":\"What does Neural Architecture Search have to do with how Deci creates its models?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vTXxxh0xBl0"
      },
      "source": [
        "Look at the entire response  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGBkR1ewxHWY",
        "outputId": "780c8083-3f53-4fd7-adb7-70280d8bafae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What does Neural Architecture Search have to do with how Deci creates its models?',\n",
              " 'result': 'Deci uses Neural Architecture Search (NAS) technology, specifically AutoNAC, to create efficient and effective neural network architectures for its models. AutoNAC intelligently searches a large space of possible architectures and zeroes in on the most promising ones. This technology allows Deci to automate the development of superior neural networks and optimize the accuracy and speed of its models.',\n",
              " 'source_documents': [Document(page_content='Neural Architecture Search is define the architecture search space. For YOLO-NAS, our researchers took inspiration from the basic blocks of YOLOv6 and YOLOv8. With the architecture and training regime in place, our researchers harnessed the power of AutoNAC. It intelligently searched a vast space of ~10^14 possible architectures, ultimately zeroing in on three final networks that promised outstanding results. The result is a family of architectures with a novel quantization-friendly basic', metadata={'source': 'https://deeplearningdaily.substack.com/p/unleashing-the-power-of-yolo-nas', 'title': 'Unleashing the Power of YOLO-NAS: A New Era in Object Detection and Computer Vision', 'description': 'The Future of Computer Vision is Here', 'language': 'en'}),\n",
              "  Document(page_content='Deci’s suite of Large Language Models and text-to-Image models, with DeciCoder leading the charge, is spearheading the movement to address this gap.DeciCoder’s efficiency is evident when compared to other top-tier models. Owing to its innovative architecture, DeciCoder surpasses models like SantaCoder in both accuracy and speed. The innovative elements of DeciCoder’s architecture were generated using Deci’s proprietary Neural Architecture Search technology, AutoNAC™.\\xa0\\nAnother Win for AutoNAC', metadata={'source': \"https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/#:~:text=DeciCoder's%20unmatched%20throughput%20and%20low,re%20obsessed%20with%20AI%20efficiency.\", 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}),\n",
              "  Document(page_content='The quest for the “optimal” neural network architecture has historically been a labor-intensive manual exploration. While this manual approach often yields results, it is highly time consuming and often falls short in pinpointing the most efficient neural networks. The AI community recognized the promise of Neural Architecture Search (NAS) as a potential game-changer, automating the development of superior neural networks. However, the computational demands of traditional NAS methods limited', metadata={'source': \"https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/#:~:text=DeciCoder's%20unmatched%20throughput%20and%20low,re%20obsessed%20with%20AI%20efficiency.\", 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}),\n",
              "  Document(page_content='This new model is fast and accurate, offering the best accuracy-latency tradeoff among existing object detection models on the market. This accomplishment was made possible by Deci’s AutoNAC neural architecture search technology, which efficiently constructs deep learning models for any task and hardware.', metadata={'source': 'https://deci.ai/blog/yolo-nas-object-detection-foundation-model/', 'title': 'YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Architecture Search', 'description': 'The new YOLO-NAS architecture sets a new frontier for object detection tasks, offering the best accuracy and latency tradeoff performance.', 'language': 'en-US'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want just the response"
      ],
      "metadata": {
        "id": "2kYiibKxzENe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1JOCbQZzC0R",
        "outputId": "3af839e0-4c74-4e8d-dc43-d78e61cfc034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deci utilizes Neural Architecture Search (NAS) technology, specifically their proprietary AutoNAC technology, to automatically generate and optimize the architecture of their models. Neural Architecture Search helps Deci in efficiently constructing deep learning models for various tasks and hardware.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And you can get the source like so:"
      ],
      "metadata": {
        "id": "agbQB4A_zZrm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV8rFTyST_nD",
        "outputId": "af675b72-ef5e-44ff-b051-547a8626468e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='Neural Architecture Search is define the architecture search space. For YOLO-NAS, our researchers took inspiration from the basic blocks of YOLOv6 and YOLOv8. With the architecture and training regime in place, our researchers harnessed the power of AutoNAC. It intelligently searched a vast space of ~10^14 possible architectures, ultimately zeroing in on three final networks that promised outstanding results. The result is a family of architectures with a novel quantization-friendly basic', metadata={'source': 'https://deeplearningdaily.substack.com/p/unleashing-the-power-of-yolo-nas', 'title': 'Unleashing the Power of YOLO-NAS: A New Era in Object Detection and Computer Vision', 'description': 'The Future of Computer Vision is Here', 'language': 'en'}), Document(page_content='Deci’s suite of Large Language Models and text-to-Image models, with DeciCoder leading the charge, is spearheading the movement to address this gap.DeciCoder’s efficiency is evident when compared to other top-tier models. Owing to its innovative architecture, DeciCoder surpasses models like SantaCoder in both accuracy and speed. The innovative elements of DeciCoder’s architecture were generated using Deci’s proprietary Neural Architecture Search technology, AutoNAC™.\\xa0\\nAnother Win for AutoNAC', metadata={'source': \"https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/#:~:text=DeciCoder's%20unmatched%20throughput%20and%20low,re%20obsessed%20with%20AI%20efficiency.\", 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}), Document(page_content='The quest for the “optimal” neural network architecture has historically been a labor-intensive manual exploration. While this manual approach often yields results, it is highly time consuming and often falls short in pinpointing the most efficient neural networks. The AI community recognized the promise of Neural Architecture Search (NAS) as a potential game-changer, automating the development of superior neural networks. However, the computational demands of traditional NAS methods limited', metadata={'source': \"https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/#:~:text=DeciCoder's%20unmatched%20throughput%20and%20low,re%20obsessed%20with%20AI%20efficiency.\", 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}), Document(page_content='This new model is fast and accurate, offering the best accuracy-latency tradeoff among existing object detection models on the market. This accomplishment was made possible by Deci’s AutoNAC neural architecture search technology, which efficiently constructs deep learning models for any task and hardware.', metadata={'source': 'https://deci.ai/blog/yolo-nas-object-detection-foundation-model/', 'title': 'YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Architecture Search', 'description': 'The new YOLO-NAS architecture sets a new frontier for object detection tasks, offering the best accuracy and latency tradeoff performance.', 'language': 'en-US'})]\n"
          ]
        }
      ],
      "source": [
        "print(response['source_documents'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-3BqcQJTBu2",
        "outputId": "203856f7-7897-48cc-ad6c-e4330c24b736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "response = qa_with_sources_chain({\"query\":\"What is DeciCoder\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbsKa0nKu-XP",
        "outputId": "1bddf350-2c2f-4956-bec5-c52f6d62b902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DeciCoder is a 1B-parameter open-source Large Language Model (LLM) for code generation. It has a 2048-context window, permissively licensed, delivers a 3.5x increase in throughput, improved accuracy on the HumanEval benchmark, and smaller memory usage compared to widely-used code generation LLMs such as SantaCoder.\n"
          ]
        }
      ],
      "source": [
        "print(response['result'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RwqP62Uu9Tc",
        "outputId": "2923f8be-c722-4556-a750-cf6be2c837d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "response = qa_with_sources_chain({\"query\":\"Write a blog about Deci and how it used NAS to generate YOLO-NAS and DeciCoder\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qivMMWHMvFqe",
        "outputId": "473a160b-a0c7-4531-b1c5-40b89c611627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deci, a company focused on pushing the boundaries of accuracy and efficiency, has introduced a new architecture called YOLO-NAS. YOLO-NAS is a benchmark for object detection that has the potential to drive innovation and unlock new possibilities across various industries and research domains.\n",
            "\n",
            "Deci has showcased its robust capabilities with the DeciCoder model, which consistently outperforms models like SantaCoder. By leveraging AutoNAC, Deci was able to generate an architecture that is both efficient and powerful.\n",
            "\n",
            "Deci's use of NAS (Neural Architecture Search) played a pivotal role in the development of YOLO-NAS. NAS is a technique that automates the design process of neural networks, allowing for the discovery of optimized architectures. By deploying NAS, Deci was able to achieve state-of-the-art performance on object detection with YOLO-NAS.\n",
            "\n",
            "The integration of NAS in the development of YOLO-NAS and DeciCoder showcases Deci's commitment to pushing the boundaries of AI innovation. With the YOLO-NAS architecture and DeciCoder, Deci aims to provide advanced solutions for various use cases, such as running on edge devices, optimizing generative AI models, reducing cloud costs, shortening development time, and maximizing data center utilization.\n",
            "\n",
            "Deci's focus on accuracy, efficiency, and innovation through the use of NAS sets them apart in the industry. Their dedication to driving progress in object detection and AI research makes them a valuable player in the field.\n"
          ]
        }
      ],
      "source": [
        "print(response['result'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a2cbab83c45400cb700856842884a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f03bd4473e4a4e3fa367d217fe35a967",
              "IPY_MODEL_d86aa4ee08774a6c93339efed4494e62",
              "IPY_MODEL_4d2e5394611d4f329086b0b027c711e1"
            ],
            "layout": "IPY_MODEL_e86b649aef4f4ccf92285a22da674660"
          }
        },
        "f03bd4473e4a4e3fa367d217fe35a967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f656d2849a2e407a9a68ec149fa336ac",
            "placeholder": "​",
            "style": "IPY_MODEL_79140df95ca54de3b982f6d1a020fa3b",
            "value": "Fetching 9 files: 100%"
          }
        },
        "d86aa4ee08774a6c93339efed4494e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_343b915e04ea4421a6d18c0cff735621",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2e625b76ff14f2bac32458e402a37e7",
            "value": 9
          }
        },
        "4d2e5394611d4f329086b0b027c711e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdcbb7cd39e8483283c686dab62b127f",
            "placeholder": "​",
            "style": "IPY_MODEL_634ea3ab03d24ed6828bd272c54bd733",
            "value": " 9/9 [00:00&lt;00:00, 228.76it/s]"
          }
        },
        "e86b649aef4f4ccf92285a22da674660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f656d2849a2e407a9a68ec149fa336ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79140df95ca54de3b982f6d1a020fa3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "343b915e04ea4421a6d18c0cff735621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e625b76ff14f2bac32458e402a37e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdcbb7cd39e8483283c686dab62b127f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634ea3ab03d24ed6828bd272c54bd733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}